{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.listdir('dataset/images/office_chairs/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate classes.txt with from folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='dataset/meta/classes.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "def generate_classes():\n",
    "\n",
    "  directory_path = \"dataset/images\"\n",
    "\n",
    "  classes = [folder for folder in os.listdir(\n",
    "      directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n",
    "\n",
    "  # Write the class names to the metadata file\n",
    "  with open(\"dataset/meta/classes.txt\", \"w\") as file:\n",
    "    print(file)\n",
    "    file.write(\"\\n\".join(classes))\n",
    "\n",
    "  return classes\n",
    "\n",
    "\n",
    "classes = generate_classes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='dataset/meta/labels.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "def generate_labels():\n",
    "\n",
    "  directory_path = \"dataset/images\"\n",
    "\n",
    "  labels = [\n",
    "      os.path.splitext(folder)[0].replace(\"_\", \" \").title()\n",
    "      for folder in os.listdir(\n",
    "      directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n",
    "\n",
    "\n",
    "  # Write the class names to the metadata file\n",
    "  with open(\"dataset/meta/labels.txt\", \"w\") as file:\n",
    "    print(file)\n",
    "    file.write(\"\\n\".join(labels))\n",
    "\n",
    "generate_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    }
   ],
   "source": [
    "def generate_test_train():\n",
    "    test_images_json = {}\n",
    "    test_images = []\n",
    "    train_images_json = {}\n",
    "    train_images = []\n",
    "\n",
    "    directory_path = 'dataset/images'\n",
    "\n",
    "    folders = os.listdir(directory_path)\n",
    "\n",
    "    \n",
    "    for folder in folders:\n",
    "\n",
    "        if os.path.isdir(os.path.join(directory_path, folder)):\n",
    "            files =  os.listdir(f'dataset/images/{folder}/')\n",
    "\n",
    "            images = [(folder+\"/\"+ os.path.splitext(file)[0])\n",
    "                    for file in files if file.endswith(\".jpg\")]\n",
    "\n",
    "            x = len(images)//2\n",
    "            \n",
    "            test_images_json[folder] = images[:x]\n",
    "            train_images_json[folder] = images[x:]\n",
    "\n",
    "            test_images += images[:x]\n",
    "            train_images +=images[x:]\n",
    "\n",
    "        else:\n",
    "            print(folder)\n",
    "        \n",
    "    with open(\"dataset/meta/test.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(test_images))\n",
    "\n",
    "    with open(\"dataset/meta/test.json\", \"w\") as json_file:\n",
    "        json.dump(test_images_json,json_file,indent=4)\n",
    "\n",
    "    with open(\"dataset/meta/train.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(train_images))\n",
    "\n",
    "    with open(\"dataset/meta/train.json\", \"w\") as json_file:\n",
    "        json.dump(train_images_json,json_file,indent=4)\n",
    "\n",
    "\n",
    "generate_test_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open('dataset.tar.gz','w:gz') as tar:\n",
    "  tar.add('dataset/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Office Chairs'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "(\"office_chairs\").replace(\"_\", \" \").title()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
